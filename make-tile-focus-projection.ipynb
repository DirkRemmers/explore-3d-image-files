{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use:\n",
    "- Setup your conda environment and install packages (Ask Dirk for help if needed)\n",
    "- Download your lif file and put it in the 'test-files' folder\n",
    "- Run the first 3 cells and select the file of interest\n",
    "- Run the 4th cell and select which images you want to get the maximum projection images from\n",
    "- Run the last cell and find your images in the 'maximum-projections' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from readlif.reader import LifFile\n",
    "import numpy as np\n",
    "import napari\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from skimage import filters, util, draw\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions\n",
    "def collect_images(raw_data, img_sel):\n",
    "    image_dict_list = []\n",
    "\n",
    "    # check how many stacks, channels and mosaics there are\n",
    "    raw_image = raw_data.get_image(img_sel)\n",
    "    image_name = raw_image.name\n",
    "    scale = tuple(abs(1/x) for x in raw_image.scale if x != None)\n",
    "    z_nr_list = list(range(0,len([i for i in raw_image.get_iter_z()])))\n",
    "    c_nr_list = list(range(0,len([i for i in raw_image.get_iter_c()])))\n",
    "    m_nr_list = list(range(0,len([i for i in raw_image.get_iter_m()])))\n",
    "    DimX = raw_image.dims[0]\n",
    "    DimY = raw_image.dims[1]\n",
    "    DimZ = raw_image.dims[2]\n",
    "\n",
    "    # get info on if it is a mosaic tile\n",
    "    M_positions = raw_image.mosaic_position # list with lenght of nr mosaics, each tuple contains (FieldX, FieldY, PosX, PosY)\n",
    "    mosaic_list = list(range(0,len(M_positions)))\n",
    "    mosaic_indication = 1\n",
    "    if mosaic_list == []:\n",
    "        mosaic_list = [0]\n",
    "        mosaic_indication = 0 \n",
    "\n",
    "    for m in m_nr_list:\n",
    "        # collect info\n",
    "        image_dict = {}\n",
    "        image_dict['image_name'] = image_name\n",
    "        image_dict['i_nr'] = img_sel\n",
    "        image_dict['m_nr'] = m\n",
    "        image_dict['scale'] = scale\n",
    "        image_dict['M_positions'] = M_positions\n",
    "        image_dict['DimX'] = DimX\n",
    "        image_dict['DimY'] = DimY\n",
    "        image_dict['DimZ'] = DimZ\n",
    "        image_dict['bitdepth'] = raw_image.info['bit_depth'][0]\n",
    "        # create 2d numpy array's per channel\n",
    "        channel_dict = {}\n",
    "        for c_nr in c_nr_list:\n",
    "            for z_nr in z_nr_list:\n",
    "                if z_nr == 0:\n",
    "                    layers = []\n",
    "                \n",
    "                layer = np.asarray(raw_image.get_frame(z = z_nr, t = 0, c = c_nr, m = m))\n",
    "                layers.append(layer)\n",
    "            layers = np.stack(layers, axis = 2)  \n",
    "            image_dict[f'channel_{c_nr}_image'] = layers\n",
    "        \n",
    "        image_dict_list.append(image_dict)\n",
    "    return image_dict_list\n",
    "\n",
    "def get_rgb(color):\n",
    "    if color == 'blue':\n",
    "        rgb = (0,0,1)\n",
    "    elif color == 'green':\n",
    "        rgb = (0,1,0)\n",
    "    elif color == 'red':\n",
    "        rgb = (1,0,0)\n",
    "    elif color == 'yellow':\n",
    "        rgb = (1,1,0)\n",
    "    elif color == 'cyan':\n",
    "        rgb = (0,1,1)\n",
    "    elif color == 'magenta':\n",
    "        rgb = (1,0,1)\n",
    "    return rgb\n",
    "\n",
    "def convert_intensity_range(img, target_type_min, target_type_max, target_type, min_quantile = False, max_quantile = False, input_bits = False):\n",
    "    imin = img.min()\n",
    "    # if no input bits is given, we want to transform the intensity range, not the type\n",
    "    if input_bits == False:\n",
    "        # correct if the image is binary and find min value\n",
    "        if imin == False:\n",
    "            img = img*1\n",
    "            imin = img.min()\n",
    "        if min_quantile != False:\n",
    "            imin = np.quantile(img, q = min_quantile)\n",
    "            \n",
    "        # find max value\n",
    "        imax = img.max()\n",
    "        if max_quantile != False:\n",
    "            imax = np.quantile(img, q = max_quantile)\n",
    "    # if the input bits is given, we want to change the bitdepth, so we want to use the entire range\n",
    "    else:\n",
    "        if input_bits == 8:\n",
    "            imin = 0\n",
    "            imax = 255\n",
    "        elif input_bits == 16:\n",
    "            imin = 0\n",
    "            imax = 65535\n",
    "        elif input_bits == 32:\n",
    "            imin = 0\n",
    "            imax = 2147483647\n",
    "    \n",
    "    # build new image\n",
    "    a = (target_type_max - target_type_min) / (imax - imin)\n",
    "    b = target_type_max - a * imax\n",
    "    new_img = (a * img + b)\n",
    "    new_img[new_img>255] = 255\n",
    "    new_img[new_img<0] = 0\n",
    "    new_img = new_img.astype(target_type)\n",
    "    return new_img\n",
    "\n",
    "def findHomography(image_1_kp, image_2_kp, matches):\n",
    "    image_1_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "    image_2_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "\n",
    "    for i in range(0,len(matches)):\n",
    "        image_1_points[i] = image_1_kp[matches[i].queryIdx].pt\n",
    "        image_2_points[i] = image_2_kp[matches[i].trainIdx].pt\n",
    "\n",
    "\n",
    "    homography, mask = cv2.findHomography(image_1_points, image_2_points, cv2.RANSAC, ransacReprojThreshold=2.0)\n",
    "\n",
    "    return homography\n",
    "\n",
    "def doLap(image):\n",
    "\n",
    "    # YOU SHOULD TUNE THESE VALUES TO SUIT YOUR NEEDS\n",
    "    kernel_size = 9         # Size of the laplacian window\n",
    "    blur_size = 9          # How big of a kernal to use for the gaussian blur\n",
    "                            # Generally, keeping these two values the same or very close works well\n",
    "                            # Also, odd numbers, please...\n",
    "\n",
    "    blurred = cv2.GaussianBlur(image, (blur_size,blur_size), 0)\n",
    "    return cv2.Laplacian(blurred, cv2.CV_64F, ksize=kernel_size)\n",
    "\n",
    "def focus_stack(images):\n",
    "    \"\"\"\n",
    "    inspiration from here:\n",
    "    https://github.com/cmcguinness/focusstack/blob/master/main.py\n",
    "    \"\"\"\n",
    "\n",
    "    laps = []\n",
    "    for i in range(len(images)):\n",
    "        laps.append(doLap(cv2.cvtColor(images[i],cv2.COLOR_BGR2GRAY)))\n",
    "\n",
    "    laps = np.asarray(laps)\n",
    "    output = np.zeros(shape=images[0].shape, dtype=images[0].dtype)\n",
    "\n",
    "    abs_laps = np.absolute(laps)\n",
    "    maxima = abs_laps.max(axis=0)\n",
    "    bool_mask = abs_laps == maxima\n",
    "    mask = bool_mask.astype(np.uint8)\n",
    "    for i in range(0,len(images)):\n",
    "        output = cv2.bitwise_not(images[i],output, mask=mask[i])\n",
    "\t\t\n",
    "    return 255-output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06bda4bbced495d8ca3576a2c9a4c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Image name', options=('SA_22.083_08-07-2022-new.lif', '22.088_22.103_TH_20220816.lif', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify file\n",
    "location = 'test-files'\n",
    "file_list = [f for f in os.listdir(location) if os.path.isfile(os.path.join(location, f))]\n",
    "\n",
    "file_selection = widgets.Dropdown(options = file_list, description = 'Image name')\n",
    "display(file_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3968bdce56a1435f8595028db522d1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Image name', options=('All', '03%_1', '03%_2', '03%_3', '05%_1', '05%_2', '05%_3'), valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0154eaa28e13443389e688e9463166de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Scale bar size', options=(100, 250, 500, 750, 1000), value=100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify image and scale bar\n",
    "raw_data = LifFile(f\"{location}/{file_selection.value}\")\n",
    "image_list = list(range(0,len([i for i in raw_data.get_iter_image()])))\n",
    "image_name_list = []\n",
    "for i in image_list:\n",
    "    raw_image = raw_data.get_image(i)\n",
    "    image_name_list.append(raw_image.name)\n",
    "\n",
    "image_selection = widgets.Dropdown(options = ['All'] + image_name_list, description = 'Image name')\n",
    "display(image_selection)\n",
    "\n",
    "scale_bar_selection = widgets.Dropdown(options = [100, 250, 500, 750, 1000], description = 'Scale bar size')\n",
    "display(scale_bar_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the images\n",
    "#  select the right order of colors in the image: (channel 0 has color 0, channel 1 has color 1 etc...)\n",
    "color_list = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'gray']\n",
    "\n",
    "# select the folder in which you want to save your images\n",
    "focus_projection_folder = 'focus_projection_images'\n",
    "\n",
    "# load the data and get a list of all image numbers\n",
    "raw_data = LifFile(f\"{location}/{file_selection.value}\")\n",
    "\n",
    "if image_selection.value == 'All':\n",
    "    image_list = list(range(0,len([i for i in raw_data.get_iter_image()])))\n",
    "else:\n",
    "    image_list = [n for n, x in enumerate(image_name_list) if x == image_selection.value]\n",
    "\n",
    "# make the focus projection images per image\n",
    "for i in image_list:\n",
    "    # get the raw image\n",
    "    raw_image = raw_data.get_image(i)\n",
    "    # image_name = raw_image.name.split('/')[-1]\n",
    "    image_name = raw_image.name.replace('/', '-')\n",
    "    image_dict_list = collect_images(raw_data, i)\n",
    "    for image_dict in image_dict_list:\n",
    "        focus_dict = {}\n",
    "        for n, (name, channel_image) in enumerate([(name, img) for name, img in image_dict.items() if 'channel' in name ]):\n",
    "            channel_image = convert_intensity_range(channel_image, 0, 255, input_bits=image_dict['bitdepth'], target_type=np.uint8)\n",
    "            # make channel stack\n",
    "            channel_stack = []\n",
    "            for z in range(channel_image.shape[2]):\n",
    "                channel_stack.append(cv2.cvtColor(channel_image[:,:,z], cv2.COLOR_GRAY2BGR))\n",
    "            focus_channel_image = convert_intensity_range(np.max(focus_stack(channel_stack), axis = 2), 0, 255, input_bits=image_dict['bitdepth'], target_type=np.uint8)\n",
    "\n",
    "            # save the focus projection image of this channel, and assign a color\n",
    "            focus_dict[f'{name}_focus_projection'] = {\"image\" : focus_channel_image, 'color' : color_list[n]}\n",
    "        \n",
    "        # get the m_nr\n",
    "        m_nr = image_dict['m_nr']\n",
    "\n",
    "        # build focus projection image\n",
    "        empty_image = np.zeros_like(focus_dict['channel_0_image_focus_projection']['image'])\n",
    "        default_color_image = np.dstack((empty_image, empty_image, empty_image))\n",
    "        red_image = default_color_image[:,:,0]\n",
    "        green_image = default_color_image[:,:,1]\n",
    "        blue_image = default_color_image[:,:,2]\n",
    "\n",
    "        # build the masked image, start with the default image\n",
    "        for image_channel in focus_dict.keys():\n",
    "            image, color = focus_dict[image_channel].values()\n",
    "            print\n",
    "            # change the color into rgb signals\n",
    "            rgb = get_rgb(color)\n",
    "            # fill in the image in the right color channels\n",
    "            if rgb[0] > 0:\n",
    "                red_image = np.dstack((red_image, image))\n",
    "            if rgb[1] > 0:\n",
    "                green_image = np.dstack((green_image, image))\n",
    "            if rgb[2] > 0:\n",
    "                blue_image = np.dstack((blue_image, image))\n",
    "        \n",
    "        # use maximum value if there are multiple stacks\n",
    "        if len(red_image.shape)>2:\n",
    "            red_image = np.max(red_image, axis = 2)\n",
    "        if len(green_image.shape)>2:\n",
    "            green_image = np.max(green_image, axis = 2)\n",
    "        if len(blue_image.shape)>2:\n",
    "            blue_image = np.max(blue_image, axis = 2)\n",
    "        \n",
    "        # design scalebar\n",
    "        scale_x = image_dict['scale'][0]\n",
    "        scale_bar_length = scale_bar_selection.value\n",
    "        pxls_for_scale_bar_x = int(scale_bar_length/scale_x)\n",
    "        pxls_for_scale_bar_y = 5\n",
    "        start = ((image.shape[0]-pxls_for_scale_bar_x-30), (image.shape[1]-pxls_for_scale_bar_y-30))\n",
    "        extent = (pxls_for_scale_bar_x, pxls_for_scale_bar_y)\n",
    "        rr, cc = draw.rectangle(start, extent=extent, shape = image.shape)\n",
    "\n",
    "        # insert rectangle\n",
    "        red_image[cc,rr] = 255\n",
    "        green_image[cc,rr] = 255\n",
    "        blue_image[cc,rr] = 255\n",
    "        \n",
    "        # create the color image with dimensions (x, y, (r, g, b))\n",
    "        color_image = np.dstack((red_image, green_image, blue_image))\n",
    "        image_for_saving = Image.fromarray(convert_intensity_range(color_image, 0, 255, np.uint8, input_bits=8))   \n",
    "\n",
    "        # design text\n",
    "        scale_text = f'{scale_bar_length} um'\n",
    "        font = ImageFont.truetype('DejaVuSansMono.ttf', 13, encoding='unic', )\n",
    "\n",
    "        # draw text on the scale bar\n",
    "        pil_draw = ImageDraw.Draw(image_for_saving)\n",
    "        pil_draw.text((start[0]+int((pxls_for_scale_bar_x*0.35)),start[1]-20), scale_text, (255, 255, 255), font=font)\n",
    "\n",
    "        #save the image with the correct name in the correct location\n",
    "        image_for_saving.save(f\"{focus_projection_folder}/{image_name}_{m_nr}.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('image-analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2614d2f8eb5189b57b8ddd674157c9ffc8a25fbb1b8dea4923aea03678f03553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
